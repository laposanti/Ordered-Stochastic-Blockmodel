max_clust=3
min_clust= 3
max_number_games = 100
N_iter = 10000
alpha= 0.5
gamma_vec = rep(1,min_clust)
beta_max = .8
set.seed(my_seed)
iteration_title = paste("seed", my_seed, "K",min_clust, "alpha" ,alpha, sep = "")
print(iteration_title)
synth_power = simulating_tournament_powerlaw(N=N,alpha = alpha,beta_max = beta_max,min_clust = min_clust,max_clust = max_clust , M = M, n_ij_max =max_number_games, gamma_vec = gamma_vec )
#synth = simulating_tournament_test(N=N,alpha = 1,beta = 3,min_clust = min_clust,max_clust = max_clust , M = M, n_ij_max =max_number_games )
synth_matches = synth_power$matches_results
synth_players = synth_power$z_true
synth_p = synth_power$p_true
K_true = synth_power$K_true
df_fast =df_aux_fast(synth_matches,synth_players,synth_p)
p_ij.true = synth_p
z.true = synth_players$z
z_mat_true=vec2mat(z.true)
matrix_z_p_true = p_ij.true%*%t(z_mat_true)
p_n_true = z_mat_true%*%matrix_z_p_true
n_ij_matrix = matrix(0,N,N)
for(i in 1:M){
n_ij_matrix[synth_matches$player_1[i], synth_matches$player_2[i]] =  synth_matches$n_ij[i]
n_ij_matrix[synth_matches$player_2[i], synth_matches$player_1[i]] =  synth_matches$n_ij[i]
}
y_ij_matrix= matrix(0,N,N)
for(i in 1:M){
y_ij_matrix[synth_matches$player_1[i], synth_matches$player_2[i]] =  synth_matches$y_ij[i]
y_ij_matrix[synth_matches$player_2[i], synth_matches$player_1[i]] =  synth_matches$n_ij[i] - synth_matches$y_ij[i]
}
z.true = synth_players$z
labels_available=1:K_true
#selecting just those values such that there is inside a non-0 entry
upper.tri_n_ij = upper.tri(n_ij_matrix)
upper.tri_y_ij = upper.tri(y_ij_matrix)
non_negative_n_ij = which(upper.tri_n_ij & n_ij_matrix > 0, arr.ind = T)
non_negative_y_ij = which(upper.tri_y_ij & y_ij_matrix > 0, arr.ind = T)
#retrieving the non-0 values
n_ij = n_ij_matrix[non_negative_n_ij]
y_ij = y_ij_matrix[non_negative_n_ij]
p_ij.true = synth_p
z.true = synth_players$z
z_mat_true=vec2mat(z.true)
matrix_z_p_true = p_ij.true%*%t(z_mat_true)
p_n_true = z_mat_true%*%matrix_z_p_true
p_ij_true =  p_n_true[non_negative_n_ij]
if(round(sum(dbinom(y_ij,n_ij,p_ij_true,log=T)),2) == round(get_A(df_fast$n_ij,df_fast$y_ij,pij = df_fast$p_ij),2)){
print("METROPOLIS: CLEAR!")}
#Containers for z
#---
z.container = matrix(0,N,N_iter)
A_seq = matrix(0,N_iter,1)
#Initialization for the z vector
#---
init = kmeans(x = y_ij_matrix,centers =K_true)$cluster
adj.rand.index(init,z.true)
z_current= init
z.container[,1] = z_current
#Containers for p
#---
alpha.container = matrix(0,N_iter,1)
p.container = array(0,c(K_true,K_true,N_iter))
#Initialization for the p matrix
#---
alpha_current = 1
p_current = simulating_POMM_powerlaw(K_true,alpha_current,beta_max = beta_max)
alpha.container[1] = alpha_current
p.container[,,1] = p_current$matrix
#Setting up quantities needed within computations
# here we are transforming a Nx1 vector, containg labels 1...K into
# NXK matrix. z_mat_current[i,k] =1 if node i is in cluster k
z_mat_current= vec2mat(z_current)
n_k_current = colSums(z_mat_current)
#creating an NxN matrix where p_n_current[i,j] is the probability that player i wins vs player j
matrix_z_p_current = p_current$matrix%*%t(z_mat_current)
p_n_current = z_mat_current%*%matrix_z_p_current
p_ij_current =  p_n_current[non_negative_n_ij]
A_seq[1] = sum(dbinom(y_ij, n_ij, p_ij_current, log=T)) + l_like_p_ij(p_current$matrix,p_current$truncations)
#containers for the counts of accepted proposals
acc.count_z = 0
acc.count_p = 0
#setting time tracker
pb=txtProgressBar(min=1,max=N_iter)
j=2
#READY TO BOMB!
while (j < N_iter + 1) {
setTxtProgressBar(pb, j)
#Complete sweeep of z vector
#----
sweeping_order = sample(x=c(1:N),size=N, replace=F)
for(i in sweeping_order){
#proposing a new label
new_label = sample(x=labels_available,size=1)
#updating labels
z_prime = z_current
z_prime[i] = new_label
#computing the new victory probabilities
while(TRUE){
z_mat_prime= vec2mat(z_prime)
if(ncol(z_mat_prime) == K_true){
break
} else {
#if there is an error, resample new_label and try again
new_label = sample(x=labels_available,size=1)
z_prime[i] = new_label
}
}
matrix_z_prime_p_current = p_current$matrix%*%t(z_mat_prime)
p_n_z_prime = z_mat_prime%*%matrix_z_prime_p_current
p_ij_z_prime =  p_n_z_prime[non_negative_n_ij]
n_k_prime = colSums(z_mat_prime)
#acceptance ratio
r = (sum(dbinom(y_ij, n_ij, p_ij_z_prime, log=T)) + ddirichlet_multinomial(N,K_true,n_k = n_k_prime,my_alpha = gamma_vec)) -
(sum(dbinom(y_ij, n_ij, p_ij_current, log = T)) + ddirichlet_multinomial(N,K_true,n_k = n_k_current ,my_alpha = gamma_vec))
alpha_r = min(1, exp(r))
u = runif(1)
#if accepted
if(u<alpha_r){
acc.count_z = acc.count_z + 1
z_current=z_prime
n_k_current = n_k_prime
p_ij_current= p_ij_z_prime
#if not accepted
}
z.container[, j] = z_current
}
#Update of the P matrix
#----
sigma_prime = 1
z_mat_current = vec2mat(z_current)
#all possible combinations of i,j entries for matrix P
entries = expand.grid(c(1:K_true), c(1:K_true))
for(iii in 0:(K_true-1)){
#proposing a new alpha
alpha_prime <- sample_norm_trunc(1,m = alpha_current,s =sigma_prime,a = 0.005,b=3)
#generating a proposal matrix
p_prime = simulating_POMM_powerlaw(K_true,alpha_prime,beta_max)
#recovering entries for diag iii for iii=0,...,K_true-1
entries_diag = cbind(entries[which(entries$Var2 -entries$Var1 == iii),])
p_scanning = p_current$matrix
#substituing just the diagonal iii
p_scanning[cbind(entries_diag[,1],entries_diag[,2])] = p_prime$matrix[cbind(entries_diag[,1],entries_diag[,2])]
#tranforming data
matrix_z_p_scanning  = p_scanning%*%t(z_mat_current)
p_n_scanning = z_mat_current%*%matrix_z_p_scanning
p_ij_scanning =  p_n_scanning[non_negative_n_ij]
#modifying alos the (iii+1)th truncation
p_scanning.truncations = p_current$truncations
p_scanning.truncations[iii+2] = p_prime$truncations[iii+2]
#adjusting alpha with new value
y_log = log(p_scanning.truncations - 0.5)[-1]
fit <- lm(y_log ~ x_points)
alpha_scanning = coef(fit)[2]
r = (sum(dbinom(y_ij, n_ij, p_ij_scanning, log=T)) +  l_like_p_ij(p_scanning,p_scanning.truncations)+dlnorm_trunc(alpha_prime,.1,2,0.00001,5)) -
(sum(dbinom(y_ij, n_ij, p_ij_current, log = T)) + l_like_p_ij(p_current$matrix,p_current$truncations)+dlnorm_trunc(alpha_current,.1,2,0.00001,5) )
alpha_r = min(1, exp(r))
u = runif(1)
if(u<r){
acc.count_p = acc.count_p+1
p_current$matrix = p_scanning
p_current$truncations = p_scanning.truncations
alpha_current = alpha_scanning
p_ij_current = p_ij_scanning
}
}
#storing results for diagnostics
p.container[,,j] = p_current$matrix
alpha.container[j]= alpha_current
A_seq[j] = sum(dbinom(y_ij, n_ij, p_ij_current, log=T)) +  l_like_p_ij(p_current$matrix,p_current$truncations)
j=j+1
}
#diagnostic for z
#-----
#proposal performance
acceptance_rate= acc.count_z/(N*N_iter)*100
#mixing
# ts.plot(A_seq[-c(1:N_iter*0.5)], main="Traceplot of p(y_ij|z,P) p(z) p(P)",
#   xlab = "Iterations", ylab ="p(y_ij|z,P) p(z) p(P)")
# dev.off()
# acf(A_seq[-c(1:N_iter*0.5)],main="Autocorrelation plot",
#     xlab = "Lag", ylab ="ACF")
# dev.off()
#estimates
similarity_matrix = pr_cc(z.container[,-c(1:N_iter*0.5)])
point_est = minVI(similarity_matrix)$cl
adj.rand.index(point_est, z.true)
similarity_plot(y_ij_matrix,z.true,z.true)
dev.off()
similarity_plot(similarity_matrix,z.true,z.true)
dev.off()
#diagnostic for P
#-----
acceptance_rate_p  = (acc.count_p/N_iter)*100
plot(ts(alpha.container), main = "Traceplot of alpha values")
abline(h = .5, col = "red", lty = 2)
# Create a data frame containing the observations
df_alpha <- data.frame(alpha_est = alpha.container)
# Create the plot
# ggplot(df_alpha, aes(x = alpha_est)) +
#   geom_density(fill = "purple", alpha = 0.5) +
#   geom_vline(aes(xintercept = mean(alpha_est)), color = "blue") +
#   geom_vline(aes(xintercept = alpha), color = "red")
for(i in 1:K_true){
for(j in 1:K_true){
print(mean(p.container[i,j,]) - synth_p[i,j])
}
}
mse_table = matrix(0,K_true,K_true)
for(i in 1:K_true){
for(j in 1:K_true){
mse_table[i,j]= (mean(p.container[i,j,]) - synth_p[i,j])
}
}
mse_table%>% pander::pander()
mse_total = sum(mse_table[upper.tri(mse_table)]**2)/((K_true*(K_true-1))/2)
burnin_p = p.container[,,-(N_iter*0.5)]
plots = list()
for(i in 1:K_true) {
for(j in 1:K_true) {
y_try = data.frame(y = as.vector(burnin_p[i, j,]))
p1 = ggplot(y_try, aes(y)) +
geom_density(fill = "dodgerblue", alpha = 0.5) +
scale_x_log10() +
geom_vline(xintercept = synth_p[i, j], color = "red")+
xlab("probability") +
ylab("Density") +
ggtitle(paste("Density of entry ", i, ",", j, sep = ""))
plots[[length(plots) + 1]] <- p1
}
}
p_combined = patchwork::wrap_plots(plots, ncol = K_true, nrow = K_true)
p_combined
png(as.character(paste("adjacencypomm",iteration_title,".png",sep = "")),width = 800, height = 540)
similarity_plot(y_ij_matrix,z.true,z.true)
dev.off()
png(as.character(paste("similaritypomm",iteration_title,".png",sep = "")),width = 800, height = 540)
similarity_plot(similarity_matrix,z.true,z.true)
dev.off()
# png(as.character(paste("heatmap_mse_pomm",iteration_title,".png",sep = "")),width = 400, height = 400)
# heat_map_blue(matrix = mse_table, "heatmap_mse")
# dev.off()
mse_iterations_pomm[iteration_title] = sqrt(mse_total)
rand_index_list_pomm[iteration_title] = adj.rand.index(point_est, z.true)
alpha_iterations_pomm[iteration_title] = mean(alpha.container[-c(1:N_iter*0.5)])
my_seed = my_seed+1
}
my_seed =12
while(my_seed<=13){
# for(p in 1:length(alpha_list)){
#   for(pp in 1:length(K_list)){
#Hyperparameters
N=100
a=1
b=1
K_max=4
M=3800
max_clust=3
min_clust= 3
max_number_games = 100
N_iter = 20000
alpha= 0.5
gamma_vec = rep(1,min_clust)
beta_max = .8
set.seed(my_seed)
iteration_title = paste("seed", my_seed, "K",min_clust, "alpha" ,alpha, sep = "")
print(iteration_title)
synth_power = simulating_tournament_powerlaw(N=N,alpha = alpha,beta_max = beta_max,min_clust = min_clust,max_clust = max_clust , M = M, n_ij_max =max_number_games, gamma_vec = gamma_vec )
#synth = simulating_tournament_test(N=N,alpha = 1,beta = 3,min_clust = min_clust,max_clust = max_clust , M = M, n_ij_max =max_number_games )
synth_matches = synth_power$matches_results
synth_players = synth_power$z_true
synth_p = synth_power$p_true
K_true = synth_power$K_true
df_fast =df_aux_fast(synth_matches,synth_players,synth_p)
p_ij.true = synth_p
z.true = synth_players$z
z_mat_true=vec2mat(z.true)
matrix_z_p_true = p_ij.true%*%t(z_mat_true)
p_n_true = z_mat_true%*%matrix_z_p_true
n_ij_matrix = matrix(0,N,N)
for(i in 1:M){
n_ij_matrix[synth_matches$player_1[i], synth_matches$player_2[i]] =  synth_matches$n_ij[i]
n_ij_matrix[synth_matches$player_2[i], synth_matches$player_1[i]] =  synth_matches$n_ij[i]
}
y_ij_matrix= matrix(0,N,N)
for(i in 1:M){
y_ij_matrix[synth_matches$player_1[i], synth_matches$player_2[i]] =  synth_matches$y_ij[i]
y_ij_matrix[synth_matches$player_2[i], synth_matches$player_1[i]] =  synth_matches$n_ij[i] - synth_matches$y_ij[i]
}
z.true = synth_players$z
labels_available=1:K_true
#selecting just those values such that there is inside a non-0 entry
upper.tri_n_ij = upper.tri(n_ij_matrix)
upper.tri_y_ij = upper.tri(y_ij_matrix)
non_negative_n_ij = which(upper.tri_n_ij & n_ij_matrix > 0, arr.ind = T)
non_negative_y_ij = which(upper.tri_y_ij & y_ij_matrix > 0, arr.ind = T)
#retrieving the non-0 values
n_ij = n_ij_matrix[non_negative_n_ij]
y_ij = y_ij_matrix[non_negative_n_ij]
p_ij.true = synth_p
z.true = synth_players$z
z_mat_true=vec2mat(z.true)
matrix_z_p_true = p_ij.true%*%t(z_mat_true)
p_n_true = z_mat_true%*%matrix_z_p_true
p_ij_true =  p_n_true[non_negative_n_ij]
if(round(sum(dbinom(y_ij,n_ij,p_ij_true,log=T)),2) == round(get_A(df_fast$n_ij,df_fast$y_ij,pij = df_fast$p_ij),2)){
print("METROPOLIS: CLEAR!")}
#Containers for z
#---
z.container = matrix(0,N,N_iter)
A_seq = matrix(0,N_iter,1)
#Initialization for the z vector
#---
init = kmeans(x = y_ij_matrix,centers =K_true)$cluster
adj.rand.index(init,z.true)
z_current= init
z.container[,1] = z_current
#Containers for p
#---
alpha.container = matrix(0,N_iter,1)
p.container = array(0,c(K_true,K_true,N_iter))
#Initialization for the p matrix
#---
alpha_current = 1
p_current = simulating_POMM_powerlaw(K_true,alpha_current,beta_max = beta_max)
alpha.container[1] = alpha_current
p.container[,,1] = p_current$matrix
#Setting up quantities needed within computations
# here we are transforming a Nx1 vector, containg labels 1...K into
# NXK matrix. z_mat_current[i,k] =1 if node i is in cluster k
z_mat_current= vec2mat(z_current)
n_k_current = colSums(z_mat_current)
#creating an NxN matrix where p_n_current[i,j] is the probability that player i wins vs player j
matrix_z_p_current = p_current$matrix%*%t(z_mat_current)
p_n_current = z_mat_current%*%matrix_z_p_current
p_ij_current =  p_n_current[non_negative_n_ij]
A_seq[1] = sum(dbinom(y_ij, n_ij, p_ij_current, log=T)) + l_like_p_ij(p_current$matrix,p_current$truncations)
#containers for the counts of accepted proposals
acc.count_z = 0
acc.count_p = 0
#setting time tracker
pb=txtProgressBar(min=1,max=N_iter)
j=2
#READY TO BOMB!
while (j < N_iter + 1) {
setTxtProgressBar(pb, j)
#Complete sweeep of z vector
#----
sweeping_order = sample(x=c(1:N),size=N, replace=F)
for(i in sweeping_order){
#proposing a new label
new_label = sample(x=labels_available,size=1)
#updating labels
z_prime = z_current
z_prime[i] = new_label
#computing the new victory probabilities
while(TRUE){
z_mat_prime= vec2mat(z_prime)
if(ncol(z_mat_prime) == K_true){
break
} else {
#if there is an error, resample new_label and try again
new_label = sample(x=labels_available,size=1)
z_prime[i] = new_label
}
}
matrix_z_prime_p_current = p_current$matrix%*%t(z_mat_prime)
p_n_z_prime = z_mat_prime%*%matrix_z_prime_p_current
p_ij_z_prime =  p_n_z_prime[non_negative_n_ij]
n_k_prime = colSums(z_mat_prime)
#acceptance ratio
r = (sum(dbinom(y_ij, n_ij, p_ij_z_prime, log=T)) + ddirichlet_multinomial(N,K_true,n_k = n_k_prime,my_alpha = gamma_vec)) -
(sum(dbinom(y_ij, n_ij, p_ij_current, log = T)) + ddirichlet_multinomial(N,K_true,n_k = n_k_current ,my_alpha = gamma_vec))
alpha_r = min(1, exp(r))
u = runif(1)
#if accepted
if(u<alpha_r){
acc.count_z = acc.count_z + 1
z_current=z_prime
n_k_current = n_k_prime
p_ij_current= p_ij_z_prime
#if not accepted
}
z.container[, j] = z_current
}
#Update of the P matrix
#----
sigma_prime = .5
z_mat_current = vec2mat(z_current)
#all possible combinations of i,j entries for matrix P
entries = expand.grid(c(1:K_true), c(1:K_true))
for(iii in 0:(K_true-1)){
#proposing a new alpha
alpha_prime <- sample_norm_trunc(1,m = alpha_current,s =sigma_prime,a = 0.005,b=3)
#generating a proposal matrix
p_prime = simulating_POMM_powerlaw(K_true,alpha_prime,beta_max)
#recovering entries for diag iii for iii=0,...,K_true-1
entries_diag = cbind(entries[which(entries$Var2 -entries$Var1 == iii),])
p_scanning = p_current$matrix
#substituing just the diagonal iii
p_scanning[cbind(entries_diag[,1],entries_diag[,2])] = p_prime$matrix[cbind(entries_diag[,1],entries_diag[,2])]
#tranforming data
matrix_z_p_scanning  = p_scanning%*%t(z_mat_current)
p_n_scanning = z_mat_current%*%matrix_z_p_scanning
p_ij_scanning =  p_n_scanning[non_negative_n_ij]
#modifying alos the (iii+1)th truncation
p_scanning.truncations = p_current$truncations
p_scanning.truncations[iii+2] = p_prime$truncations[iii+2]
#adjusting alpha with new value
y_log = log(p_scanning.truncations - 0.5)[-1]
fit <- lm(y_log ~ x_points)
alpha_scanning = coef(fit)[2]
r = (sum(dbinom(y_ij, n_ij, p_ij_scanning, log=T)) +  l_like_p_ij(p_scanning,p_scanning.truncations)+dlnorm_trunc(alpha_prime,.1,2,0.00001,5)) -
(sum(dbinom(y_ij, n_ij, p_ij_current, log = T)) + l_like_p_ij(p_current$matrix,p_current$truncations)+dlnorm_trunc(alpha_current,.1,2,0.00001,5) )
alpha_r = min(1, exp(r))
u = runif(1)
if(u<r){
acc.count_p = acc.count_p+1
p_current$matrix = p_scanning
p_current$truncations = p_scanning.truncations
alpha_current = alpha_scanning
p_ij_current = p_ij_scanning
}
}
#storing results for diagnostics
p.container[,,j] = p_current$matrix
alpha.container[j]= alpha_current
A_seq[j] = sum(dbinom(y_ij, n_ij, p_ij_current, log=T)) +  l_like_p_ij(p_current$matrix,p_current$truncations)
j=j+1
}
#diagnostic for z
#-----
#proposal performance
acceptance_rate= acc.count_z/(N*N_iter)*100
#mixing
# ts.plot(A_seq[-c(1:N_iter*0.5)], main="Traceplot of p(y_ij|z,P) p(z) p(P)",
#   xlab = "Iterations", ylab ="p(y_ij|z,P) p(z) p(P)")
# dev.off()
# acf(A_seq[-c(1:N_iter*0.5)],main="Autocorrelation plot",
#     xlab = "Lag", ylab ="ACF")
# dev.off()
#estimates
similarity_matrix = pr_cc(z.container[,-c(1:N_iter*0.5)])
point_est = minVI(similarity_matrix)$cl
adj.rand.index(point_est, z.true)
similarity_plot(y_ij_matrix,z.true,z.true)
dev.off()
similarity_plot(similarity_matrix,z.true,z.true)
dev.off()
#diagnostic for P
#-----
acceptance_rate_p  = (acc.count_p/N_iter)*100
plot(ts(alpha.container), main = "Traceplot of alpha values")
abline(h = .5, col = "red", lty = 2)
# Create a data frame containing the observations
df_alpha <- data.frame(alpha_est = alpha.container)
# Create the plot
# ggplot(df_alpha, aes(x = alpha_est)) +
#   geom_density(fill = "purple", alpha = 0.5) +
#   geom_vline(aes(xintercept = mean(alpha_est)), color = "blue") +
#   geom_vline(aes(xintercept = alpha), color = "red")
for(i in 1:K_true){
for(j in 1:K_true){
print(mean(p.container[i,j,]) - synth_p[i,j])
}
}
mse_table = matrix(0,K_true,K_true)
for(i in 1:K_true){
for(j in 1:K_true){
mse_table[i,j]= (mean(p.container[i,j,]) - synth_p[i,j])
}
}
mse_table%>% pander::pander()
mse_total = sum(mse_table[upper.tri(mse_table)]**2)/((K_true*(K_true-1))/2)
burnin_p = p.container[,,-(N_iter*0.5)]
plots = list()
for(i in 1:K_true) {
for(j in 1:K_true) {
y_try = data.frame(y = as.vector(burnin_p[i, j,]))
p1 = ggplot(y_try, aes(y)) +
geom_density(fill = "dodgerblue", alpha = 0.5) +
scale_x_log10() +
geom_vline(xintercept = synth_p[i, j], color = "red")+
xlab("probability") +
ylab("Density") +
ggtitle(paste("Density of entry ", i, ",", j, sep = ""))
plots[[length(plots) + 1]] <- p1
}
}
p_combined = patchwork::wrap_plots(plots, ncol = K_true, nrow = K_true)
p_combined
png(as.character(paste("adjacencypomm",iteration_title,".png",sep = "")),width = 800, height = 540)
similarity_plot(y_ij_matrix,z.true,z.true)
dev.off()
png(as.character(paste("similaritypomm",iteration_title,".png",sep = "")),width = 800, height = 540)
similarity_plot(similarity_matrix,z.true,z.true)
dev.off()
# png(as.character(paste("heatmap_mse_pomm",iteration_title,".png",sep = "")),width = 400, height = 400)
# heat_map_blue(matrix = mse_table, "heatmap_mse")
# dev.off()
mse_iterations_pomm[iteration_title] = sqrt(mse_total)
rand_index_list_pomm[iteration_title] = adj.rand.index(point_est, z.true)
alpha_iterations_pomm[iteration_title] = mean(alpha.container[-c(1:N_iter*0.5)])
my_seed = my_seed+1
}
mse_table%>% pander::pander()
plot(ts(alpha.container), main = "Traceplot of alpha values")
similarity_plot(y_ij_matrix,z.true,z.true)
dev.off()
similarity_plot(similarity_matrix,z.true,z.true)
dev.off()
