llik = as.matrix(llik)
z_pivot <- z_chain[,which.max(llik)]
# Apply function to each chunk
run_label_switch <- label.switching(method = "ECR" ,
zpivot = z_pivot ,
z = t(z_chain),
K = k)
num_samples=length(seq(burnin, N_iter, 2))
P_s_table_save <-P_s_table$table
P_chain_permuted <- P_s_table$P_permuted
P_est_relabeled<- P_s_table$P_hat
permutation_z = run_label_switch$permutations$ECR
chain_relabeled = matrix(NA, nrow=nrow(Y_ij), ncol = N_iter-burnin)
for(i in 1:ncol(chain_relabeled)){
chain_relabeled[,i] <- permutation_z[i,][z_chain[,i]]
}
P_permuted = array(NA, dim=c(K,K,nrow(permutation_z)))
for(i in 1:num_samples){
# Permute the rows of matrix P
P_permuted[,,i] <- P_burned[permutation_z[i,], permutation_z[i,],i]
}
P_burned <- P_permuted
LL <- matrix(0, ((nrow(Y_ij)*(nrow(Y_ij)-1))/2), num_samples)
p=0
for(ii in seq(1, num_samples,1)){
p=p+1
z_ii<- chain_relabeled[,ii]
P_ii <- P_burned[,,ii]
theta_ii<- inverse_logit_f(P_ii)
P_ij<- calculate_victory_probabilities(vec2mat_0_P(z_ii,P = theta_ii), theta_ii)
LL[,p]<- dbinom(x = Y_ij[upper.tri(Y_ij)], size = N_ij[upper.tri(N_ij)],prob = P_ij[upper.tri(P_ij)], log = T)
}
LLik_sum_i_ = colSums(LL)
if (i %% 6 ==0 || i ==1){
z_chain = i_$est_containers$z[,-burnin]
psm<- comp.psm(t(z_chain))
point_est_z_min_VI <- minVI(psm = psm)$cl
point_est_z_MAP <- z_chain[,which.max(LLik_sum_i_)]
dist_min_VI = vi.dist(point_est_z_min_VI,i_$ground_truth$z)
dist_MAP = vi.dist(point_est_z_MAP,i_$ground_truth$z)
}else{
dist_min_VI =NA
dist_MAP =NA
}
expected_evidence = sum(LLik_sum_i_)*(1/num_samples)
log_z_t = rbind(log_z_t, data.frame(t = i_$t , expected_evidence= expected_evidence, sd= sd(LLik_sum_i_),
k=k,z_est_min_VI= dist_min_VI ,
z_est_MAP= dist_MAP))
}
}
log_z_t
i_ <- readRDS(file = paste0(data_wd,"/",filenames[i]))
Y_ij = i_$Y_ij
N_ij = i_$N_ij
N_iter = ncol(i_$est_containers$z)
burnin= N_iter-10000
num_samples = N_iter - burnin
k
data_wd = paste0(main_dir, k,"/")
filenames <- list.files(pattern = paste0(true_model),path = data_wd)
for(i in 1:length(filenames)){
#---------------------------------------------------------------------------
#---------------------------------------------------------------------------
i_ <- readRDS(file = paste0(data_wd,"/",filenames[i]))
Y_ij = i_$Y_ij
N_ij = i_$N_ij
N_iter = ncol(i_$est_containers$z)
burnin= N_iter-10000
num_samples = N_iter - burnin
P_burned = i_$est_containers$P[,,-c(burnin:N_iter)]
P_est = apply(P_burned, c(1,2), mean)
theta = inverse_logit_f(P_est)
z_chain = i_$est_containers$z[,-c(1:burnin)]
llik<- apply(z_chain, 2, function(z_chain)
log_lik_f_binom(N = N_ij,
Y = Y_ij,
z = z_chain,
P = theta))
llik = as.matrix(llik)
z_pivot <- z_chain[,which.max(llik)]
# Apply function to each chunk
run_label_switch <- label.switching(method = "ECR" ,
zpivot = z_pivot ,
z = t(z_chain),
K = k)
num_samples=length(seq(burnin, N_iter, 2))
P_s_table_save <-P_s_table$table
P_chain_permuted <- P_s_table$P_permuted
P_est_relabeled<- P_s_table$P_hat
permutation_z = run_label_switch$permutations$ECR
chain_relabeled = matrix(NA, nrow=nrow(Y_ij), ncol = N_iter-burnin)
for(i in 1:ncol(chain_relabeled)){
chain_relabeled[,i] <- permutation_z[i,][z_chain[,i]]
}
P_permuted = array(NA, dim=c(K,K,nrow(permutation_z)))
for(i in 1:num_samples){
# Permute the rows of matrix P
P_permuted[,,i] <- P_burned[permutation_z[i,], permutation_z[i,],i]
}
P_burned <- P_permuted
LL <- matrix(0, ((nrow(Y_ij)*(nrow(Y_ij)-1))/2), num_samples)
p=0
for(ii in seq(1, num_samples,1)){
p=p+1
z_ii<- chain_relabeled[,ii]
P_ii <- P_burned[,,ii]
theta_ii<- inverse_logit_f(P_ii)
P_ij<- calculate_victory_probabilities(vec2mat_0_P(z_ii,P = theta_ii), theta_ii)
LL[,p]<- dbinom(x = Y_ij[upper.tri(Y_ij)], size = N_ij[upper.tri(N_ij)],prob = P_ij[upper.tri(P_ij)], log = T)
}
LLik_sum_i_ = colSums(LL)
if (i %% 6 ==0 || i ==1){
z_chain = i_$est_containers$z[,-burnin]
psm<- comp.psm(t(z_chain))
point_est_z_min_VI <- minVI(psm = psm)$cl
point_est_z_MAP <- z_chain[,which.max(LLik_sum_i_)]
dist_min_VI = vi.dist(point_est_z_min_VI,i_$ground_truth$z)
dist_MAP = vi.dist(point_est_z_MAP,i_$ground_truth$z)
}else{
dist_min_VI =NA
dist_MAP =NA
}
expected_evidence = sum(LLik_sum_i_)*(1/num_samples)
log_z_t = rbind(log_z_t, data.frame(t = i_$t , expected_evidence= expected_evidence, sd= sd(LLik_sum_i_),
k=k,z_est_min_VI= dist_min_VI ,
z_est_MAP= dist_MAP))
}
P_chain_permuted
filenames[i]
i_ <- readRDS(file = paste0(data_wd,"/",filenames[i]))
Y_ij = i_$Y_ij
N_ij = i_$N_ij
N_iter = ncol(i_$est_containers$z)
burnin= N_iter-10000
num_samples = N_iter - burnin
P_burned = i_$est_containers$P[,,-c(burnin:N_iter)]
P_est = apply(P_burned, c(1,2), mean)
P_est
theta = inverse_logit_f(P_est)
z_chain = i_$est_containers$z[,-c(1:burnin)]
llik<- apply(z_chain, 2, function(z_chain)
log_lik_f_binom(N = N_ij,
Y = Y_ij,
z = z_chain,
P = theta))
llik = as.matrix(llik)
llik
permutation_z = run_label_switch$permutations$ECR
chain_relabeled = matrix(NA, nrow=nrow(Y_ij), ncol = N_iter-burnin)
for(i in 1:ncol(chain_relabeled)){
chain_relabeled[,i] <- permutation_z[i,][z_chain[,i]]
}
P_permuted = array(NA, dim=c(K,K,nrow(permutation_z)))
K
K = i_$ground_truth$K
N_iter = ncol(i_$est_containers$z)
burnin= N_iter-10000
num_samples = N_iter - burnin
P_burned = i_$est_containers$P[,,-c(burnin:N_iter)]
P_est = apply(P_burned, c(1,2), mean)
theta = inverse_logit_f(P_est)
z_chain = i_$est_containers$z[,-c(1:burnin)]
llik<- apply(z_chain, 2, function(z_chain)
log_lik_f_binom(N = N_ij,
Y = Y_ij,
z = z_chain,
P = theta))
llik = as.matrix(llik)
z_pivot <- z_chain[,which.max(llik)]
# Apply function to each chunk
run_label_switch <- label.switching(method = "ECR" ,
zpivot = z_pivot ,
z = t(z_chain),
K = k)
num_samples=length(seq(burnin, N_iter, 2))
permutation_z = run_label_switch$permutations$ECR
chain_relabeled = matrix(NA, nrow=nrow(Y_ij), ncol = N_iter-burnin)
for(i in 1:ncol(chain_relabeled)){
chain_relabeled[,i] <- permutation_z[i,][z_chain[,i]]
}
P_permuted = array(NA, dim=c(K,K,nrow(permutation_z)))
for(i in 1:num_samples){
# Permute the rows of matrix P
P_permuted[,,i] <- P_burned[permutation_z[i,], permutation_z[i,],i]
}
K,
K
N_ij = i_$N_ij
K = i_$ground_truth$K
K
K = nrow(i_$est_containers$P)
K
N_iter = ncol(i_$est_containers$z)
burnin= N_iter-10000
num_samples = N_iter - burnin
P_burned = i_$est_containers$P[,,-c(burnin:N_iter)]
P_est = apply(P_burned, c(1,2), mean)
theta = inverse_logit_f(P_est)
z_chain = i_$est_containers$z[,-c(1:burnin)]
llik<- apply(z_chain, 2, function(z_chain)
log_lik_f_binom(N = N_ij,
Y = Y_ij,
z = z_chain,
P = theta))
llik = as.matrix(llik)
z_pivot <- z_chain[,which.max(llik)]
# Apply function to each chunk
run_label_switch <- label.switching(method = "ECR" ,
zpivot = z_pivot ,
z = t(z_chain),
K = k)
num_samples=length(seq(burnin, N_iter, 2))
permutation_z = run_label_switch$permutations$ECR
chain_relabeled = matrix(NA, nrow=nrow(Y_ij), ncol = N_iter-burnin)
for(i in 1:ncol(chain_relabeled)){
chain_relabeled[,i] <- permutation_z[i,][z_chain[,i]]
}
P_permuted = array(NA, dim=c(K,K,nrow(permutation_z)))
for(i in 1:num_samples){
# Permute the rows of matrix P
P_permuted[,,i] <- P_burned[permutation_z[i,], permutation_z[i,],i]
}
P_burned <- P_permuted
LL <- matrix(0, ((nrow(Y_ij)*(nrow(Y_ij)-1))/2), num_samples)
p=0
for(ii in seq(1, num_samples,1)){
p=p+1
z_ii<- chain_relabeled[,ii]
P_ii <- P_burned[,,ii]
theta_ii<- inverse_logit_f(P_ii)
P_ij<- calculate_victory_probabilities(vec2mat_0_P(z_ii,P = theta_ii), theta_ii)
LL[,p]<- dbinom(x = Y_ij[upper.tri(Y_ij)], size = N_ij[upper.tri(N_ij)],prob = P_ij[upper.tri(P_ij)], log = T)
}
LLik_sum_i_ = colSums(LL)
if (i %% 6 ==0 || i ==1){
z_chain = i_$est_containers$z[,-burnin]
psm<- comp.psm(t(z_chain))
point_est_z_min_VI <- minVI(psm = psm)$cl
point_est_z_MAP <- z_chain[,which.max(LLik_sum_i_)]
dist_min_VI = vi.dist(point_est_z_min_VI,i_$ground_truth$z)
dist_MAP = vi.dist(point_est_z_MAP,i_$ground_truth$z)
}else{
dist_min_VI =NA
dist_MAP =NA
}
expected_evidence = sum(LLik_sum_i_)*(1/num_samples)
log_z_t = rbind(log_z_t, data.frame(t = i_$t , expected_evidence= expected_evidence, sd= sd(LLik_sum_i_),
k=k,z_est_min_VI= dist_min_VI ,
z_est_MAP= dist_MAP))
for(k in 4:5){
data_wd = paste0(main_dir, k,"/")
filenames <- list.files(pattern = paste0(true_model),path = data_wd)
for(i in 1:length(filenames)){
#---------------------------------------------------------------------------
#---------------------------------------------------------------------------
i_ <- readRDS(file = paste0(data_wd,"/",filenames[i]))
Y_ij = i_$Y_ij
N_ij = i_$N_ij
K = nrow(i_$est_containers$P)
N_iter = ncol(i_$est_containers$z)
burnin= N_iter-10000
num_samples = N_iter - burnin
P_burned = i_$est_containers$P[,,-c(burnin:N_iter)]
P_est = apply(P_burned, c(1,2), mean)
theta = inverse_logit_f(P_est)
z_chain = i_$est_containers$z[,-c(1:burnin)]
llik<- apply(z_chain, 2, function(z_chain)
log_lik_f_binom(N = N_ij,
Y = Y_ij,
z = z_chain,
P = theta))
llik = as.matrix(llik)
z_pivot <- z_chain[,which.max(llik)]
# Apply function to each chunk
run_label_switch <- label.switching(method = "ECR" ,
zpivot = z_pivot ,
z = t(z_chain),
K = k)
num_samples=length(seq(burnin, N_iter, 2))
permutation_z = run_label_switch$permutations$ECR
chain_relabeled = matrix(NA, nrow=nrow(Y_ij), ncol = N_iter-burnin)
for(i in 1:ncol(chain_relabeled)){
chain_relabeled[,i] <- permutation_z[i,][z_chain[,i]]
}
P_permuted = array(NA, dim=c(K,K,nrow(permutation_z)))
for(i in 1:num_samples){
# Permute the rows of matrix P
P_permuted[,,i] <- P_burned[permutation_z[i,], permutation_z[i,],i]
}
P_burned <- P_permuted
LL <- matrix(0, ((nrow(Y_ij)*(nrow(Y_ij)-1))/2), num_samples)
p=0
for(ii in seq(1, num_samples,1)){
p=p+1
z_ii<- chain_relabeled[,ii]
P_ii <- P_burned[,,ii]
theta_ii<- inverse_logit_f(P_ii)
P_ij<- calculate_victory_probabilities(vec2mat_0_P(z_ii,P = theta_ii), theta_ii)
LL[,p]<- dbinom(x = Y_ij[upper.tri(Y_ij)], size = N_ij[upper.tri(N_ij)],prob = P_ij[upper.tri(P_ij)], log = T)
}
LLik_sum_i_ = colSums(LL)
if (i %% 6 ==0 || i ==1){
z_chain = i_$est_containers$z[,-burnin]
psm<- comp.psm(t(z_chain))
point_est_z_min_VI <- minVI(psm = psm)$cl
point_est_z_MAP <- z_chain[,which.max(LLik_sum_i_)]
dist_min_VI = vi.dist(point_est_z_min_VI,i_$ground_truth$z)
dist_MAP = vi.dist(point_est_z_MAP,i_$ground_truth$z)
}else{
dist_min_VI =NA
dist_MAP =NA
}
expected_evidence = sum(LLik_sum_i_)*(1/num_samples)
log_z_t = rbind(log_z_t, data.frame(t = i_$t , expected_evidence= expected_evidence, sd= sd(LLik_sum_i_),
k=k,z_est_min_VI= dist_min_VI ,
z_est_MAP= dist_MAP))
}
}
source("~/Desktop/Nial/POMM_pairwise/POMMs/model_auxiliary_functions/Generating_SimulationData.R", echo=TRUE)
log_z_t = log_z_t[-1,]
log_z_t %>% saveRDS("/Users/lapo_santi/Desktop/Nial/weekly material/model_choice/simulation_fromK3.RDS")
log_z_t1 <- log_z_t %>%
arrange(k, t) %>%
group_by(k) %>%
mutate(t_plus1 = lead(t)) %>%
mutate(t_mi = t_plus1 - t) %>%
mutate(height = (expected_evidence + lead(expected_evidence)) / 2)
my_table <- log_z_t1 %>%
dplyr::select(t, expected_evidence,k) %>%
round(digits = 3)
# Split data by k and generate tables
tables <- lapply(unique(my_table$k), function(k_value) {
subset_data <- filter(my_table, k == k_value) %>%
ungroup() %>%
dplyr::select(-k) %>%
slice(1,10,25,33)
kbl(t(subset_data), longtable = TRUE, booktabs = TRUE,
caption = paste("Expected deviances for the power posterior at temperature ti for models k =", k_value), escape = FALSE) %>%
kable_styling(position = "center")
})
ggplot(log_z_t,aes(x =t, group = k,color = as.factor(k))) +
geom_line(aes(y = height, color=as.factor(k)))+
labs(title = "Expected deviance", x = "t", y= "Expected Log Likelihood", color = "K", caption = "Data simulated from the SST model for K=3")+
theme_bw()
log_z_t1 <- log_z_t %>%
arrange(k, t) %>%
group_by(k) %>%
mutate(t_plus1 = lead(t)) %>%
mutate(t_mi = t_plus1 - t) %>%
mutate(height = (expected_evidence + lead(expected_evidence)) / 2)
my_table <- log_z_t1 %>%
dplyr::select(t, expected_evidence,k) %>%
round(digits = 3)
ggplot(log_z_t1,aes(x =t, group = k,color = as.factor(k))) +
geom_line(aes(y = height, color=as.factor(k)))+
labs(title = "Expected deviance", x = "t", y= "Expected Log Likelihood", color = "K", caption = "Data simulated from the SST model for K=3")+
theme_bw()
marginal_lik = data.frame(k = 2:5, marginal = rep(NA,4))
for(k_i in 2:5){
subset_data = log_z_t %>% filter(k == k_i)
ith_container = vector()
for(row_i in 1:(nrow(subset_data)-1 )){
ith_sum = (subset_data$t[row_i+1] - subset_data$t[row_i])*(subset_data$expected_evidence[row_i]+subset_data$expected_evidence[row_i+1])/2
ith_container = append(ith_container, ith_sum)
}
marginal_lik$marginal[k_i-1] = sum(ith_container)
marginal_lik$sd[k_i-1] = subset_data %>% filter(t>0.25) %>% summarise(mean_i = mean(sd)) %>% dplyr::select(mean_i) %>% as.numeric()
}
marginal_lik=marginal_lik %>% mutate(quantile_95 = 1.96*sd)
log_z_t %>% ggplot(aes(x = t, y = sd, group_by(factor(k))))+
geom_line(aes(color = factor(k)))+
labs(title = "Standard deviation of the evidence at each temperature for different Ks",
y = 'Standard error', x = "temperature", color = 'K',
caption = 'Data genenrated from the SST model with K=3')
ggplot(marginal_lik, aes(x = k, y = marginal))+
geom_errorbar(aes(ymin= marginal - quantile_95, ymax = marginal+quantile_95))+
geom_point()+
labs(title = "Approximation of marginal posterior for different models",
subtitle = "True model has K=3",
y = "Marginal posterior", x="K")
log_z_t1
log_z_t
subset_data = log_z_t %>% filter(k == k_i) %>% arrange(t)
ith_container = vector()
for(row_i in 1:(nrow(subset_data)-1 )){
ith_sum = (subset_data$t[row_i+1] - subset_data$t[row_i])*(subset_data$expected_evidence[row_i]+subset_data$expected_evidence[row_i+1])/2
ith_container = append(ith_container, ith_sum)
}
marginal_lik = data.frame(k = 2:5, marginal = rep(NA,4))
for(k_i in 2:5){
subset_data = log_z_t %>% filter(k == k_i) %>% arrange(t)
ith_container = vector()
for(row_i in 1:(nrow(subset_data)-1 )){
ith_sum = (subset_data$t[row_i+1] - subset_data$t[row_i])*(subset_data$expected_evidence[row_i]+subset_data$expected_evidence[row_i+1])/2
ith_container = append(ith_container, ith_sum)
}
marginal_lik$marginal[k_i-1] = sum(ith_container)
marginal_lik$sd[k_i-1] = subset_data %>% filter(t>0.25) %>% summarise(mean_i = mean(sd)) %>% dplyr::select(mean_i) %>% as.numeric()
}
marginal_lik=marginal_lik %>% mutate(quantile_95 = 1.96*sd)
log_z_t %>% ggplot(aes(x = t, y = sd, group_by(factor(k))))+
geom_line(aes(color = factor(k)))+
labs(title = "Standard deviation of the evidence at each temperature for different Ks",
y = 'Standard error', x = "temperature", color = 'K',
caption = 'Data genenrated from the SST model with K=3')
ggplot(marginal_lik, aes(x = k, y = marginal))+
geom_errorbar(aes(ymin= marginal - quantile_95, ymax = marginal+quantile_95))+
geom_point()+
labs(title = "Approximation of marginal posterior for different models",
subtitle = "True model has K=3",
y = "Marginal posterior", x="K")
ggplot(marginal_lik, aes(x = k, y = marginal))+
geom_bar()+
labs(title = "Approximation of marginal posterior for different models",
subtitle = "True model has K=3",
y = "Marginal posterior", x="K")
ggplot(marginal_lik, aes(x = k, y = marginal))+
geom_col()+
labs(title = "Approximation of marginal posterior for different models",
subtitle = "True model has K=3",
y = "Marginal posterior", x="K")
ggplot(marginal_lik, aes(x = k, y = marginal))+
geom_point()+
labs(title = "Approximation of marginal posterior for different models",
subtitle = "True model has K=3",
y = "Marginal posterior", x="K")
log_z_t
source("~/Desktop/Nial/POMM_pairwise/POMMs/model_auxiliary_functions/Generating_SimulationData.R", echo=TRUE)
source("~/Desktop/Nial/POMM_pairwise/POMMs/model_auxiliary_functions/Generating_SimulationData.R", echo=TRUE)
true_model = 'SST'
est_model = 'SST'
#where the data are stored
data_wd<- "./Data/Sim1_data/"
filenames <- list.files(pattern = paste0(true_model),path = data_wd)
print(filenames)
source("~/Desktop/Nial/POMM_pairwise/POMMs/Application_laucher.R", echo=TRUE)
library(doFuture)
library(progressr)
library(beepr)
library(foreach)
library(doParallel)
library(tidyverse)
library(EnvStats)
library(truncnorm)
library(dplyr)
library(ggplot2)
library(dplyr)
library(RColorBrewer)
library(truncnorm)
library(doRNG)
source("./model_auxiliary_functions/Functions_priorSST.R")
source("./Metropolis_within_Gibbs_code.R")
source("./model_auxiliary_functions/MCMC_functions.R")
estimation_control = list(z = 1,sigma_squared=1, mu_vec=1,K=0,P=1)
chains_WST = adaptive_MCMC_orderstats(Y_ij = Y_ij, N_ij = N_ij ,
estimation_control = estimation_control,
ground_truth = ground_truth,
n = n, N_iter = N_iter,n_chains = n_chains,
optimal_acceptance_rate_P = optimal_acceptance_rate_P,
optimal_acceptance_rate_mu = optimal_acceptance_rate_mu, K = K_chains,
seed = chains_seeds, model = 'WST',t=t_chains, custom_init = NA)
source("~/Desktop/Nial/POMM_pairwise/POMMs/Application_laucher.R", echo=TRUE)
traceback()
source("~/Desktop/Nial/POMM_pairwise/POMMs/Application_laucher.R", echo=TRUE)
source("~/Desktop/Nial/POMM_pairwise/POMMs/Application_laucher.R", echo=TRUE)
source("~/Desktop/Nial/POMM_pairwise/POMMs/Application_laucher.R", echo=TRUE)
source("~/Desktop/Nial/POMM_pairwise/POMMs/Application_laucher.R", echo=TRUE)
tryCatch(
for(i in 1:10){
ed^2
},
error = function(e){
message("An error occurred:\n", e)
}
)
ed=2
tryCatch(
for(i in 1:10){
ed^2
},
error = function(e){
message("An error occurred:\n", e)
}
)
ed=2
tryCatch(
for(i in 1:10){
print(ed^2)
},
error = function(e){
message("An error occurred:\n", e)
}
)
ed=2
tryCatch(
for(i in 1:10){
print(ed^i)
},
error = function(e){
message("An error occurred:\n", e)
}
)
ed='h'
tryCatch(
for(i in 1:10){
print(ed^i)
},
error = function(e){
message("An error occurred:\n", e)
}
)
source("~/Desktop/Nial/POMM_pairwise/POMMs/Application_laucher.R", echo=TRUE)
