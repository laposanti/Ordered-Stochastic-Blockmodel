#
}
#storing scales
# tau_sigma_squared_container[j]<- tau_sigma_squared
# tau_mu_vec_container[j]<- tau_mu_vec
# tau_theta_container[,,j]<- tau_theta
#
#storing results for inference
if(j > burnin & j%%thin==0){
z_container[,save_count] <- z_current
theta_container[,,save_count] <- theta_current
if(model=='SST'){
mu_vec_container[,save_count] <- mu_vec_current
}
P_current = inverse_logit_f(theta_current)
z_mat_current = vec2mat_0_P(z_current,  P_current)
P_ij_current = calculate_victory_probabilities(z_mat_current,  P_current)
A_container[,save_count] = dbinom(Y_ij[common_indices],
N_ij[common_indices],
P_ij_current[common_indices],log = T)
save_count = save_count +1
}
# #storing scales
# tau_sigma_squared_container[j]<- tau_sigma_squared
# tau_mu_vec_container[j]<- tau_mu_vec
# tau_theta_container[,,j]<- tau_theta
#
#
end_time <- Sys.time()
iteration_time<-append(iteration_time,as.numeric(difftime(end_time, start_time, units = "secs")))
if(j%%5000==0){
avg_iteration<- mean(iteration_time)
current_time <- Sys.time() # Get the current time
# Calculate the expected finishing time
expected_finishing_time <- current_time + (avg_iteration * (N_iter - j) )
formatted_expected_finishing_time <- format(expected_finishing_time, "%H:%M:%S")
p(sprintf("Chain %d: mean acc.rate z %.3f%%,
mean acc.rate theta %.3f%%,
mean acc.rate mu_vec %.3f%% single_iter_time '%*.3f' seconds, will_finish_at '%s'",
chain,
100 * mean(acc.count_z/j),
100 * mean(acc.count_theta/j),
100 * mean(acc.count_mu_vec/j),
4, avg_iteration, formatted_expected_finishing_time), class = "sticky")
}
}
if(power_posterior_apprach ==T){
acceptance_rates <- list(acc.count_theta = acc.count_theta,
acc.count_z = acc.count_z,
acc.count_mu_vec= acc.count_mu_vec)
est_containers = list(z = z_container,theta = theta_container,
mu_vec = mu_vec_container)
control_containers = list(A = A_container,
N_iter = N_iter,
thin = thin,
N_iter_eff = N_iter_eff)
st.deviations<- list(tau_theta =tau_theta_container,
tau_mu_vec= tau_mu_vec_container)
chains = list(Y_ij= Y_ij, N_ij = N_ij, ground_truth=ground_truth,est_containers=est_containers,
control_containers=control_containers, acceptance_rates= acceptance_rates,
st.deviations=st.deviations, t=t, seed= seed)
#storing the results of each chain
my_names <- paste0("chain")
my_filename <- paste0(save_dir,data_description, "Est_model",model,"_estK_",
K,"_N", n, "iteration", which(t == t_list),".RDS")
saveRDS(object = chains, file = my_filename) # saving results
}
}
A_container[,1]
A_container[,2]
save_count
P_ij_current
dim(A_container)
save_count
common_indices
sum(common_indices)
#initialising the chain
A_container <- matrix(0, nrow = sum(common_indices) , ncol = N_iter_eff)
#initialising the chain
z_container <- matrix(0, nrow = n, ncol = N_iter_eff)
if(model == 'WST'||model == 'SST'){
#initialising the chain
mu_vec_container = matrix(0, nrow = K, ncol = N_iter_eff)
#initialising the adaptive variance
tau_mu_vec <- rep(0.3, K)
tau_mu_vec_container = matrix(0,K, N_iter)
tau_mu_vec_container[,1] <- tau_mu_vec
}else{
mu_vec_container <- NA
tau_mu_vec <- NA
tau_mu_vec_container <- NA
}
#initialing theta and its adaptive variance container
theta_container = array(0, dim = c(K,K,N_iter_eff))
tau_theta_container = array(0,dim=c(K,K,N_iter_eff))
tau_theta =matrix(0.25,K,K)
tau_theta_container[,,1] = tau_theta
#containers for the counts of accepted proposals
acc.count_z = rep(1,n)
acc.count_sigma_squared=1
acc.count_mu_vec = rep(1, K)
acc.count_theta<- matrix(1,K,K)
#READY TO BOMB!
iteration_time= vector()
save_count = 0
for(j in 2:N_iter){
start_time <- Sys.time()
if (estimation_control$z == 1) {
#z UPDATE-------------------------------------------------------------
z_update = z_update_f(z = z_current, N_ij = N_ij,
Y_ij = Y_ij,theta =theta_current,
lamdabar = lamdabar,ybar=ybar,
mbar=mbar,alpha_vec = alpha_vec,
n_k = n_k,K = K,
acc.count_z = acc.count_z,
common_indices = common_indices,
labels_available = labels_available,
model = model, t=t)
llik = z_update$A_prime
z_current = z_update$z
acc.count_z = z_update$acc.moves
label_counts <- table(factor(z_current, levels = labels_available))
n_k = as.numeric(label_counts)
}
if (estimation_control$theta == 1) {
#theta UPDATE-------------------------------------------------------------
theta_update = theta_update_f(z = z_current, N_ij = N_ij,
Y_ij = Y_ij,
theta = theta_current,alpha_vec = alpha_vec,
n_k = n_k,
mu_vec = mu_vec_current,
K = K,tau_theta =tau_theta,
common_indices = common_indices,
acc.count_theta =acc.count_theta,model=model,t=t)
llik = theta_update$llik
theta_current = theta_update$theta
acc.count_theta =theta_update$acc.moves
# if(j %% 50 == 0){
#
#   for(my_p in 1:K){
#     for(my_q in my_p:K){
#
#       tau_theta[my_p,my_q] = tuning_proposal(iteration = j,
#                                              acceptance_count = acc.count_theta[my_p,my_q],
#                                              sigma = tau_theta[my_p,my_q],
#                                              acceptanceTarget = optimal_acceptance_rate_theta,
#                                              min_sigma = 0.00002)
#
#     }
#   }
# }
}
if(estimation_control$mu== 1) {
#mu UPDATE----------------------------------------------------------------
mu_update=  mu_update_f(z = z_current, N_ij = N_ij, llik=llik,
Y_ij = Y_ij,  theta =theta_current,
alpha_vec =  alpha_vec, n_k = n_k,
mu_vec = mu_vec_current,K = K,
common_indices = common_indices,
tau_mu_vec = tau_mu_vec,
acc.count_mu_vec,model,t=t)
#updating quantities
mu_vec_current = mu_update$mu_vec
acc.count_mu_vec = mu_update$acc.moves
theta_current = mu_update$theta
#
# if(j %% 50 == 0){
#   tau_mu_vec <- tuning_proposal(iteration=j,acceptance_count = acc.count_mu_vec,
#                                 sigma = tau_mu_vec,
#                                 acceptanceTarget = optimal_acceptance_rate_mu,
#                                 min_sigma = 0.002)
# }
#
}
#storing scales
# tau_sigma_squared_container[j]<- tau_sigma_squared
# tau_mu_vec_container[j]<- tau_mu_vec
# tau_theta_container[,,j]<- tau_theta
#
#storing results for inference
if(j > burnin & j%%thin==0){
save_count = save_count +1
z_container[,save_count] <- z_current
theta_container[,,save_count] <- theta_current
if(model=='SST'){
mu_vec_container[,save_count] <- mu_vec_current
}
P_current = inverse_logit_f(theta_current)
z_mat_current = vec2mat_0_P(z_current,  P_current)
P_ij_current = calculate_victory_probabilities(z_mat_current,  P_current)
A_container[,save_count] = dbinom(Y_ij[common_indices],
N_ij[common_indices],
P_ij_current[common_indices],log = T)
}
# #storing scales
# tau_sigma_squared_container[j]<- tau_sigma_squared
# tau_mu_vec_container[j]<- tau_mu_vec
# tau_theta_container[,,j]<- tau_theta
#
#
end_time <- Sys.time()
iteration_time<-append(iteration_time,as.numeric(difftime(end_time, start_time, units = "secs")))
if(j%%5000==0){
avg_iteration<- mean(iteration_time)
current_time <- Sys.time() # Get the current time
# Calculate the expected finishing time
expected_finishing_time <- current_time + (avg_iteration * (N_iter - j) )
formatted_expected_finishing_time <- format(expected_finishing_time, "%H:%M:%S")
p(sprintf("Chain %d: mean acc.rate z %.3f%%,
mean acc.rate theta %.3f%%,
mean acc.rate mu_vec %.3f%% single_iter_time '%*.3f' seconds, will_finish_at '%s'",
chain,
100 * mean(acc.count_z/j),
100 * mean(acc.count_theta/j),
100 * mean(acc.count_mu_vec/j),
4, avg_iteration, formatted_expected_finishing_time), class = "sticky")
}
}
A_container[,1]
acceptance_rates <- list(acc.count_theta =acc.count_theta, acc.count_z = acc.count_z,
acc.count_mu_vec= acc.count_mu_vec)
st.deviations<- list(tau_theta =tau_theta_container,
tau_mu_vec= tau_mu_vec_container)
est_containers = list(z = z_container,theta = theta_container, mu_vec = mu_vec_container)
control_containers = list(est_model = model,
N_iter = N_iter,
thin = thin,
N_iter_eff = N_iter_eff)
r_effs = loo::relative_eff(A_container,ncol(A_container))
ncol(A_container)
dim(A_container)
#initialising the chain
A_container <- matrix(0, ncol = sum(common_indices) , nrow = N_iter_eff)
#initialising the chain
z_container <- matrix(0, nrow = n, ncol = N_iter_eff)
if(model == 'WST'||model == 'SST'){
#initialising the chain
mu_vec_container = matrix(0, nrow = K, ncol = N_iter_eff)
#initialising the adaptive variance
tau_mu_vec <- rep(0.3, K)
tau_mu_vec_container = matrix(0,K, N_iter)
tau_mu_vec_container[,1] <- tau_mu_vec
}else{
mu_vec_container <- NA
tau_mu_vec <- NA
tau_mu_vec_container <- NA
}
#initialing theta and its adaptive variance container
theta_container = array(0, dim = c(K,K,N_iter_eff))
tau_theta_container = array(0,dim=c(K,K,N_iter_eff))
tau_theta =matrix(0.25,K,K)
tau_theta_container[,,1] = tau_theta
#containers for the counts of accepted proposals
acc.count_z = rep(1,n)
acc.count_sigma_squared=1
acc.count_mu_vec = rep(1, K)
acc.count_theta<- matrix(1,K,K)
#READY TO BOMB!
iteration_time= vector()
save_count = 0
for(j in 2:N_iter){
start_time <- Sys.time()
if (estimation_control$z == 1) {
#z UPDATE-------------------------------------------------------------
z_update = z_update_f(z = z_current, N_ij = N_ij,
Y_ij = Y_ij,theta =theta_current,
lamdabar = lamdabar,ybar=ybar,
mbar=mbar,alpha_vec = alpha_vec,
n_k = n_k,K = K,
acc.count_z = acc.count_z,
common_indices = common_indices,
labels_available = labels_available,
model = model, t=t)
llik = z_update$A_prime
z_current = z_update$z
acc.count_z = z_update$acc.moves
label_counts <- table(factor(z_current, levels = labels_available))
n_k = as.numeric(label_counts)
}
if (estimation_control$theta == 1) {
#theta UPDATE-------------------------------------------------------------
theta_update = theta_update_f(z = z_current, N_ij = N_ij,
Y_ij = Y_ij,
theta = theta_current,alpha_vec = alpha_vec,
n_k = n_k,
mu_vec = mu_vec_current,
K = K,tau_theta =tau_theta,
common_indices = common_indices,
acc.count_theta =acc.count_theta,model=model,t=t)
llik = theta_update$llik
theta_current = theta_update$theta
acc.count_theta =theta_update$acc.moves
# if(j %% 50 == 0){
#
#   for(my_p in 1:K){
#     for(my_q in my_p:K){
#
#       tau_theta[my_p,my_q] = tuning_proposal(iteration = j,
#                                              acceptance_count = acc.count_theta[my_p,my_q],
#                                              sigma = tau_theta[my_p,my_q],
#                                              acceptanceTarget = optimal_acceptance_rate_theta,
#                                              min_sigma = 0.00002)
#
#     }
#   }
# }
}
if(estimation_control$mu== 1) {
#mu UPDATE----------------------------------------------------------------
mu_update=  mu_update_f(z = z_current, N_ij = N_ij, llik=llik,
Y_ij = Y_ij,  theta =theta_current,
alpha_vec =  alpha_vec, n_k = n_k,
mu_vec = mu_vec_current,K = K,
common_indices = common_indices,
tau_mu_vec = tau_mu_vec,
acc.count_mu_vec,model,t=t)
#updating quantities
mu_vec_current = mu_update$mu_vec
acc.count_mu_vec = mu_update$acc.moves
theta_current = mu_update$theta
#
# if(j %% 50 == 0){
#   tau_mu_vec <- tuning_proposal(iteration=j,acceptance_count = acc.count_mu_vec,
#                                 sigma = tau_mu_vec,
#                                 acceptanceTarget = optimal_acceptance_rate_mu,
#                                 min_sigma = 0.002)
# }
#
}
#storing scales
# tau_sigma_squared_container[j]<- tau_sigma_squared
# tau_mu_vec_container[j]<- tau_mu_vec
# tau_theta_container[,,j]<- tau_theta
#
#storing results for inference
if(j > burnin & j%%thin==0){
save_count = save_count +1
z_container[,save_count] <- z_current
theta_container[,,save_count] <- theta_current
if(model=='SST'){
mu_vec_container[,save_count] <- mu_vec_current
}
P_current = inverse_logit_f(theta_current)
z_mat_current = vec2mat_0_P(z_current,  P_current)
P_ij_current = calculate_victory_probabilities(z_mat_current,  P_current)
A_container[save_count,] = dbinom(Y_ij[common_indices],
N_ij[common_indices],
P_ij_current[common_indices],log = T)
}
# #storing scales
# tau_sigma_squared_container[j]<- tau_sigma_squared
# tau_mu_vec_container[j]<- tau_mu_vec
# tau_theta_container[,,j]<- tau_theta
#
#
end_time <- Sys.time()
iteration_time<-append(iteration_time,as.numeric(difftime(end_time, start_time, units = "secs")))
if(j%%5000==0){
avg_iteration<- mean(iteration_time)
current_time <- Sys.time() # Get the current time
# Calculate the expected finishing time
expected_finishing_time <- current_time + (avg_iteration * (N_iter - j) )
formatted_expected_finishing_time <- format(expected_finishing_time, "%H:%M:%S")
p(sprintf("Chain %d: mean acc.rate z %.3f%%,
mean acc.rate theta %.3f%%,
mean acc.rate mu_vec %.3f%% single_iter_time '%*.3f' seconds, will_finish_at '%s'",
chain,
100 * mean(acc.count_z/j),
100 * mean(acc.count_theta/j),
100 * mean(acc.count_mu_vec/j),
4, avg_iteration, formatted_expected_finishing_time), class = "sticky")
}
}
acceptance_rates <- list(acc.count_theta =acc.count_theta, acc.count_z = acc.count_z,
acc.count_mu_vec= acc.count_mu_vec)
st.deviations<- list(tau_theta =tau_theta_container,
tau_mu_vec= tau_mu_vec_container)
est_containers = list(z = z_container,theta = theta_container, mu_vec = mu_vec_container)
control_containers = list(est_model = model,
N_iter = N_iter,
thin = thin,
N_iter_eff = N_iter_eff)
r_effs = loo::relative_eff(A_container,ncol(A_container))
dim(A_container)
r_effs = loo::relative_eff(A_container,nrow(A_container))
nrow(A_container)
dim(A_container)
r_effs = loo::relative_eff(A_container,rep(1,nrow(A_container)))
loo_model_fit = loo(A_container,cores = 1,save_psis = T,r_eff = r_effs)
loo_model_fit
n_chains = 4
optimal_acceptance_rate_theta =.44
optimal_acceptance_rate_mu = .234
seed=20
N_iter <- 6000 #number of iterations
burnin <- 3000 #number of discarded iterations
thin=15
# for(K in 3:10){
K = data_to_be_estimated$ground_truth$K
K_est = rep(K, n_chains) #number of clusters to fit
is.simulation=T
est_model = 'SST'
#where to save the data
saving_directory = "./Results/"
#Boolean: power_posterior_approach = T estimates the marginal likelihood via power posteriors
power_posterior_apprach = F
custom_init <- NA
print(paste0("Estimation of the SST model, K=", K_est))
print(paste0("Begin cycle at:", date(), "\n"))
estimation_control <- list(z = 1, sigma_squared = 0, mu_vec = 1 ,K = 0, theta = 0)
chains_SST <- adaptive_MCMC_orderstats_powerposterior(Y_ij = Y_ij, N_ij = N_ij,
saving_directory = saving_directory,
estimation_control = estimation_control,
burnin = burnin,
ground_truth = ground_truth,
n = n, N_iter = N_iter,
K_est = K_est,data_description = data_description,
seed = seed,
model = est_model,
custom_init = custom_init,
power_posterior_apprach = power_posterior_apprach,
thin=thin)
source("./model_auxiliary_functions/Functions_priorSST.R")
source("./Metropolis_within_Gibbs_code_powerposterior.R")
source("./model_auxiliary_functions/MCMC_functions.R")
subject = "lapo.santi@ucdconnect.ie"
service_account_key = "./sonic-426715-75af23aca274.json"
googledrive::drive_deauth()
googledrive::drive_auth_configure(path = "./client_secret_573831164304-jqqj3i5mhvubbkkuifvtgkfsut8lse3g.apps.googleusercontent.com.json")
googledrive::drive_auth(email = subject)
#
#
# 2
# # Get the folder (if you already have it) or specify the path where you want to upload
folder_url <- "https://drive.google.com/drive/u/1/folders/1kDXj6cq9u2fEH1Py9YBx8zoFPI9V57fR"
folder <- drive_get(as_id(folder_url))
print('Simulation study for fixed K, for K=3,4,5,6')
is.simulation=T
data_to_be_estimated = readRDS(paste0(data_directory,filenames[file]))
stopifnot(data_to_be_estimated$model == true_model)
recovery_capability = data_to_be_estimated$recovery_capability
N_ij = data_to_be_estimated$N_ij
n = nrow(N_ij)
Y_ij = data_to_be_estimated$Y_ij
ground_truth =data_to_be_estimated$ground_truth
K= nrow(data_to_be_estimated$ground_truth$theta)
data_description = paste0(true_model,K)
print(paste0("True data--->", filenames[file]))
n_chains = 4
optimal_acceptance_rate_theta =.44
optimal_acceptance_rate_mu = .234
seed=20
N_iter <- 6000 #number of iterations
burnin <- 3000 #number of discarded iterations
thin=15
# for(K in 3:10){
K = data_to_be_estimated$ground_truth$K
K_est = rep(K, n_chains) #number of clusters to fit
is.simulation=T
print(paste0("True data--->", filenames[file], "\n"))
est_model = 'SST'
#where to save the data
saving_directory = "./Results/"
#Boolean: power_posterior_approach = T estimates the marginal likelihood via power posteriors
power_posterior_apprach = F
custom_init <- NA
print(paste0("Estimation of the SST model, K=", K_est))
print(paste0("Begin cycle at:", date(), "\n"))
estimation_control <- list(z = 1, sigma_squared = 0, mu_vec = 1 ,K = 0, theta = 0)
chains_SST <- adaptive_MCMC_orderstats_powerposterior(Y_ij = Y_ij, N_ij = N_ij,
saving_directory = saving_directory,
estimation_control = estimation_control,
burnin = burnin,
ground_truth = ground_truth,
n = n, N_iter = N_iter,
K_est = K_est,data_description = data_description,
seed = seed,
model = est_model,
custom_init = custom_init,
power_posterior_apprach = power_posterior_apprach,
thin=thin)
my_names <- paste0("chain", 1:n_chains)
names(chains_SST)<- my_names
chains_SST[['recovery_level']] = recovery_capability
#where the data are stored
data_wd<- "./Data/Sim1_data/"
data_description = 'SST5'
filenames <- list.files(pattern = paste0(data_description),path = data_wd)
#where the data are stored
data_wd<- "./Data/Sim1_data/"
data_description = 'SST5'
filenames <- list.files(pattern = paste0(data_description),path = data_wd)
filenames
data_to_be_estimated <- readRDS(paste0(data_wd, "/", filenames[1]))
N_ij <- data_to_be_estimated$N_ij
n <- nrow(N_ij)
Y_ij <- data_to_be_estimated$Y_ij
K <- data_to_be_estimated$ground_truth$K
ground_truth <- data_to_be_estimated$ground_truth
choose_model_to_estimate = c('SST',"WST","Simple")
!dir.exists(saving_directory)
dir.exists(saving_directory)
#where to save the data
saving_directory = "./Results/MCMC_output/model_choice/WAIC_method/K7_true/"
# Check if the directory exists
if (!dir.exists(saving_directory)) {
# If the directory doesn't exist, create it
dir.create(saving_directory, recursive = TRUE)
message("Directory created.")
} else {
message("Directory already exists.")
}
